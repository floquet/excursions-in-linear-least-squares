\chapter{Finer Points}

A deeper look at the example.

\section{Invariances}  %    S    S    S    S    S    S    S    S    S
Invariance is a touchstone which allows for elegant discrimination of theoretical and numerical analysis. The critical insight is this: complicated problems have complicated solutions, but they retain simple invariances. Simple properties afford simple tools for checking complicated problems.

\subsection{\label{spec:translation invariance}Translation Invariance}  %   SS   SS   SS   SS   SS   SS   SS   SS   SS   SS   SS   SS
Intuitively, a translation of the coordinate system will not change the temperature measurements, which means the gradient of the temperature is invariant under translation of the coordinate system. For the example in figure \ref{fig:bar}, the temperature gradient was measured over the length of a 10 cm bar. For convenience, the end of the bar in contact with the ice bath was taken as the origin. But just as readily, that point could have been taken as $x$ = 5 cm; the end of the bar touching the boiling water bath is then 15 cm. The physics is unchanged. For an arbitrary shift of $x_{*}$ the gradient is invariant:
  \begin{equation*}   %  =   =   =   =   =
  %\begin{split}
    \nabla T = \frac{T_{1} - T_{0}} { (x_{1} + x_{*}) - (x_{0} + x_{*}) }
             = \frac{T_{1} - T_{0}} { x_{1} - x_{0} }
    %\label{eq:}
  %\end{split}
  \end{equation*}

How should the solution change? We insist the slope (gradient) remain unchanged. The origin shifts from $x_{0}$ = 0 to $x_{0}$ = $-x_{*}$, the intercept shifts according to
  \begin{equation*}   %  =   =   =   =   =
   %\begin{split}
      y(-x_{0}) = a_{0} - a_{1} x,
   %\end{split}
   %\label{eq:}
  \end{equation*}
that is, $a_{0} \to a_{0} - a_{1} x_{*}$.

\subsubsection{\label{sssec:translation}Translation}  %  SSS  SSS  SSS  SSS  SSS  SSS  SSS  SSS  SSS  SSS  SSS  SSS
Formally evaluate how the least squares solution in (??) transforms under the translation
  \begin{equation*}   %  =   =   =   =   =
  %\begin{split}
    x_{k} \rightarrow x_{k} + x_{*}
    %\label{eq:}
  %\end{split}
  \end{equation*}
The position vector $x$ can be written as the sum of the original vector plus the translation:
  \begin{equation*}   %  =   =   =   =   =
  %\begin{split}
    \mat{c}{x_{1} \\ x_{2} \\ \vdots \\x_{m}} \rightarrow
    \mat{c}{x_{1} + x_{*} \\ x_{2} + x_{*} \\ \vdots \\x_{m} + x_{*}} =
    \mat{c}{x_{1} \\ x_{2} \\ \vdots \\x_{m}} +
    \mat{c}{x_{*} \\ x_{*} \\ \vdots \\ x_{*}} .
    %\label{eq:}
  %\end{split}
  \end{equation*}
In vector notation this is
  \begin{equation}   %  =   =   =   =   =
  %\begin{split}
    x \rightarrow x + \mathbf{1}x_{*} .
    %\label{eq:}
  \label{eq:translation}
  \end{equation}

\subsubsection{Demonstrations}  %  SSS  SSS  SSS  SSS  SSS  SSS  SSS  SSS  SSS  SSS  SSS  SSS
First compute the transformation rules on the inner products using \eqref{eq:translation}:
  \begin{equation}   %  =   =   =   =   =
    \begin{split}
      \oto &\rightarrow \oto, \\
      \otx &\rightarrow \otx + x_{*} \poto, \\
      \xtx &\rightarrow \xtx + 2x_{*} \potx + x_{*}^{2} \poto, \\
      \xtt &\rightarrow \xtt + x_{*} \pott.
     \label{eq:translation:dot products}
     \end{split}
  \end{equation}
Computation of the transformation of the intercept $a_{0}$ and slope $a_{1}$ requires computation of the transformation of the determinant in \eqref{eq:get}:
  \eqref{eq:det again}:
  \begin{equation*}   %  =   =   =   =   =
    \begin{split}
      \Delta 
        &= \mydet, \\
        &\rightarrow \poto \paren{\xtx + 2x_{*} \potx + x_{*}^{2} \potx} - \paren{\otx + x_{*} \poto}^{2} , \\
        &= \Delta + \poto \paren{2x_{*} \potx + x_{*}^{2} \potx} - \paren{2x_{*} \poto\potx} - \paren{x_{*}\poto}^{2} , \\
        &= \Delta.
    %\label{eq:}
    \end{split}
  \end{equation*}
Thus the determinant is invariant under translation. Using the substitutions in \eqref{eq:translation:dot products} one can show (exercise ???) the solution parameters transform as expected:
  \begin{equation*}   %  =   =   =   =   =
   \begin{split}
      a_{0} &\rightarrow a_{0} - a_{1} x_{*}, \\
      a_{1} &\rightarrow a_{1} .
   \end{split}
   %\label{eq:}
  \end{equation*}

Homework: C to F, affine transform $T\rightarrow \alpha T + \beta$


\subsubsection{Computations}  %  SSS  SSS  SSS  SSS  SSS  SSS  SSS  SSS  SSS  SSS  SSS  SSS

The slope is invariant, the intercept:
  \begin{equation*}   %  =   =   =   =   =
    \begin{split}
      a_{1} & \rightarrow a_{1}, \\
      a_{0} & \rightarrow a_{0} - x_{*} a_{1}.
    %\label{eq:}
    \end{split}
  \end{equation*}

Predictions for $x_{*} = 1$. 
  \begin{equation}   %  =   =   =   =   =
    \begin{split}
      a_{0} & \rightarrow -\frac{827}  {180}, \\
      a_{1} & \rightarrow  \frac{1129} {120}.
    \label{eq:bev:prediction}
    \end{split}
  \end{equation}

  % = =  e q u a t i o n
  \begin{equation*}
    \begin{split}
      \mat{c}{a_{0} \\ a_{1} } 
        &= \Delta^{-1}
           \bl{
            \mat{ll}{\ps \sum x_{k}^{2} & -\sum x_{k} \\ -\sum x_{k} & \ps \sum 1}
            \mat{l}{\sum T_{k} \\ \sum T_{k} x_{k}}} , \\
        &= 540^{-1}
           \bl{
            \mat{rr}{384 & -54 \\ -54 & 9} \frac{1}{10}
            \mat{r}{4667 \\ 33\,647}} , \\
        &= \frac{1}{360}
           \bl{
           \mat{r}{1733 \\ 3387}}.
      %\label{eqn:bevington solution product}
    \end{split}
  \end{equation*}
  % = =
In agreement with \eqref{eq:bev:prediction}.

\subsubsection{Visuals}  %  SSS  SSS  SSS  SSS  SSS  SSS  SSS  SSS  SSS  SSS  SSS  SSS

Compare to figure \ref{fig:bevington soln v data}
\begin{figure}[htbp] %  figure placement: here, top, bottom, or page
   \centering
   \begin{overpic}[ scale = \myscale ]
		{\pathgraphics "bevington III"/"translate data v soln"}
		% 
    	\put(42,65){$x_{k} \rightarrow x_{k} + x_{*}$}
    	\put(50,-3){$x,$ cm}
    	\put(-10,31.5){$T, ^{\circ}$C}
	    %
   \end{overpic}
   \caption{Solution after translation along $x$ axis: the slope is invariant.}
   \label{fig:bevington translate soln v data}
\end{figure}

Compare to \ref{fig:bevington residuals}
\begin{figure}[htbp] %  figure placement: here, top, bottom, or page
   \centering
   \begin{overpic}[ scale = \myscale ]
		{\pathgraphics "bevington III"/"translate residuals"}
		% 
    	\put(50,-3){$x,$ cm}
    	\put(-25,31.5){$T_{k}-T(x_{k}), ^{\circ}$C}
	    %
   \end{overpic}
   \caption[Scatter plot of residual errors.]{Scatter plot of residual errors after translation along $x$ axis: the residuals are invariant.}
   \label{fig:bevington translate residuals}
\end{figure}

Compare to figure \ref{fig:bevington merit}
\begin{figure}[htbp]
\centering
    \begin{overpic}[ scale = \myscale ]{\pathgraphics "bevington III"/"translate merit"}
        \put(40,102){$x_{k} \rightarrow x_{k} + x_{*}$}
    	\put(50,-3){$a_{0}$}
    	\put(-5,52){$a_{1}$}
    \end{overpic}
   \label{fig:bevington translate merit}
   \caption[The merit function after translation.]{Contour plot of merit function after translation along $x$ axis: $a_{1}$ is invariant.}
\end{figure}


\subsection{Reflection Invariance}  %   SS   SS   SS   SS   SS   SS   SS   SS   SS   SS   SS   SS
A demonstration of the reflection method of \S \ref{sec:reflection invariance}.
  \begin{equation*}   %  =   =   =   =   =
  %\begin{split}
    \sum_{k=1}^{m} r^{2} = \sum_{k=1}^{m} \paren{-r}^{2}
    %\label{eq:}
  %\end{split}
  \end{equation*}

table \ref{tab:bevington solution} 

\begin{figure}[htbp] %  figure placement: here, top, bottom, or page
   \centering
   \begin{overpic}[ scale = \myscale ]
	   {\pathgraphics "bevington plus"/"reflect bars"}
        %
      	\put(50,-3) {$a_{0}$}
      	\put(-4,33) {$a_{1}$}
	      %
   \end{overpic}
   \caption{The merit function for the learning curve showing the minimum and the value.}
   \label{fig:learn:merit}
\end{figure}

\section{Fitting To Higher Orders}  %    S    S    S    S    S    S    S    S    S

\section{Removing Terms}  %    S    S    S    S    S    S    S    S    S
Here we develop a useful tool for removing isolated terms in the merit function.

Trial function for a line (polynomial expansion)
  \begin{equation*}   %  =   =   =   =   =
   %\begin{split}
      y_{k} = a_{0} + a_{1} x_{k}, \qquad k = 1, m
   %\end{split}
   %\label{eq:}
  \end{equation*}

In this instance, we can eliminate the intercept by looking at the differences between measurements. To wit,
  \begin{equation*}   %  =   =   =   =   =
   %\begin{split}
      y_{j} - y_{k} = a_{1} \paren{x_{j} - x_{k}}, \qquad \begin{cases}j=1, m-1\\ k= j+1, m\end{cases}
   %\end{split}
   \label{eq:difference jk}
  \end{equation*}
The common sense interpretation of this equation is that the difference in measurements tells us about the slope
Use the integer $p_{\nu}$, $\nu=\half n\paren{n-1}$ to keep track of the pairs of indices $(j,k)$. 
\begin{table}[htbp]
    \caption{Relating the pair index $\mu$ to the indices $j$ and $k$.}
    \begin{center}
        \begin{tabular}{ll}
        	%
					$p_{\mu}$ & $(j,k)$ \\\hline
					%
    			$p_{1}$ & (1,2) \\
    			$p_{2}$ & (1,3) \\
    			\ $\vdots$ & \ $\vdots$ \\
    			$p_{m-1}$ & $(1,m-1)$  \\
    			$p_{m}$ & $(2,1)$  \\
    			\ $\vdots$ & \ $\vdots$ \\
    			$p_{\half n\paren{n-1}}$ & $(m-1,m)$  \\
        	%
        \end{tabular}
    \end{center}
    \label{default}
\end{table}
The variable $M  = \half n\paren{n-1}$ counts the number of distinct pairs.
  \begin{equation*}   %  =   =   =   =   =
   %\begin{split}
      Y_{p_{\mu}} = a_{1} Y_{p_{\mu}}, \qquad \mu = 1, M
   %\end{split}
   \label{eq:difference jk}
  \end{equation*}
The merit function is
  \begin{equation*}   %  =   =   =   =   =
   %\begin{split}
      M(a_{1}) = \sum_{\mu=1}^{M} \paren{Y_{p_{\mu}} - a_{1} X_{p_{\mu}}}^{2}
   %\end{split}
   %\label{eq:}
  \end{equation*}
Setting the derivative with respect to $a_{1}$ equal to zero generates the solution
  \begin{equation*}   %  =   =   =   =   =
   %\begin{split}
      a_{1} = \frac{\sum_{\mu=1}^{M} X_{p_{\mu}} Y_{p_{\mu}}} {\sum_{\mu=1}^{M} X_{p_{\mu}}^{2}}
   %\end{split}
   %\label{eq:}
  \end{equation*}

This is the same answer as \eqref{???},
  \begin{equation*}   %  =   =   =   =   =
   %\begin{split}
      a_{1} = \frac{m \sum_{k=1}^{m}x_{k}y_{k} - \sum_{k=1}^{m}x_{k}\sum_{k=1}^{m}y_{k}} {m \sum_{k=1}^{m}x_{k}^{2} - \paren{\sum_{k=1}^{m}x_{k}}^{2}} .
   %\end{split}
   %\label{eq:}
  \end{equation*}
Numerator:
  \begin{equation*}   %  =   =   =   =   =
   %\begin{split}
      \sum_{j=1}^{m-1} \sum_{k=j+1}^{m} \paren{x_{j}y_{j} + x_{k}y_{k}} = (m-1) \sum_{i=1}^{m} x_{i}y_{i}
   %\end{split}
   \label{eq:rule 1}
  \end{equation*}
  \begin{equation*}   %  =   =   =   =   =
   %\begin{split}
   	  \sum_{i=1}^{m}x_{i} \sum_{i=1}^{m}y_{i} = \sum_{i=1}^{m}x_{i}y_{i} - 
      \sum_{j=1}^{m-1} \sum_{k=j+1}^{m} \paren{x_{j}y_{k} + x_{k}y_{j}} 
   %\end{split}
   \label{eq:rule 2}
  \end{equation*}


Denominator:

\endinput

%\section{Section Title}  %    S    S    S    S    S    S    S    S    S
%\subsection{Subsection Title}  %   SS   SS   SS   SS   SS   SS   SS   SS   SS   SS   SS   SS
%\subsubsection{Subsubsection Title}  %  SSS  SSS  SSS  SSS  SSS  SSS  SSS  SSS  SSS  SSS  SSS  SSS