\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {1.1}{\ignorespaces The residual error $\left \delimiter 69645069 r \right \delimiter 86422285 _{2}$ given in \textup {\hbox {\mathsurround \z@ \normalfont (\ignorespaces 1.5\hbox {}\unskip \@@italiccorr )}}.}}{5}
\contentsline {figure}{\numberline {1.2}{\ignorespaces Scalar function $\phi $ and approximations.}}{6}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {2.1}{\ignorespaces Decomposing the data vector.}}{16}
\contentsline {figure}{\numberline {2.2}{\ignorespaces Projections of the data vector.}}{19}
\contentsline {figure}{\numberline {2.3}{\ignorespaces Data vector resolved as $b = {\color {blue} {b_{ \mathcal {R} }}} + {\color {red} {b_{ \mathcal {N} }}}$.}}{20}
\contentsline {figure}{\numberline {2.4}{\ignorespaces Data vector resolved as $b + {\color {red} {b_{ \mathcal {N} }}} = {\color {blue} {b_{ \mathcal {R} }}}$.}}{20}
\contentsline {figure}{\numberline {2.5}{\ignorespaces Reflecting the data points through the solution curve.}}{21}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {3.1}{\ignorespaces A sample line.}}{24}
\contentsline {figure}{\numberline {3.2}{\ignorespaces Every point on the line satisfies the least squares criterion; the particular solution is the vector of minimum length.}}{25}
\contentsline {figure}{\numberline {3.3}{\ignorespaces The point on the line closest to the origin.}}{26}
\contentsline {figure}{\numberline {3.4}{\ignorespaces The least squares solution for \textup {\hbox {\mathsurround \z@ \normalfont (\ignorespaces 3.2\hbox {}\unskip \@@italiccorr )}} resolved into range space (blue) and null space components (red).}}{27}
\contentsline {figure}{\numberline {3.5}{\ignorespaces A contour plot of the merit function showing the particular solution (blue dot) and homogeneous solution (red dashes).}}{28}
\contentsline {figure}{\numberline {3.6}{\ignorespaces Parallel lines and the least squares solution.}}{32}
\contentsline {figure}{\numberline {3.7}{\ignorespaces Trajectory of the solution point $p(m)$ in \textup {\hbox {\mathsurround \z@ \normalfont (\ignorespaces 3.11\hbox {}\unskip \@@italiccorr )}} for $-\infty < m < \infty $.}}{34}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {4.1}{\ignorespaces Measuring the temperature of a bar.}}{42}
\contentsline {figure}{\numberline {4.2}{\ignorespaces Solution plotted against data with residual errors shown in red.}}{49}
\contentsline {figure}{\numberline {4.3}{\ignorespaces Scatter plot of residual errors.}}{50}
\contentsline {figure}{\numberline {4.4}{\ignorespaces Scatter plot of residual errors with data points connected.}}{50}
\contentsline {figure}{\numberline {4.5}{\ignorespaces The merit function.}}{51}
\contentsline {figure}{\numberline {4.6}{\ignorespaces Another look at the merit function showing the primary error ellipse (black) and contour levels (gray).}}{52}
\contentsline {figure}{\numberline {4.7}{\ignorespaces Whisker plot showing 250 randomly sampled solutions.}}{53}
\contentsline {figure}{\numberline {4.8}{\ignorespaces Scatter plot showing sampling of solutions.}}{54}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {5.1}{\ignorespaces The solution vector is the mixture of $u_{1}$ and $u_{2}$ which eliminates error.}}{63}
\contentsline {figure}{\numberline {5.2}{\ignorespaces Measurement space for the Bevington example}}{64}
\contentsline {figure}{\numberline {5.3}{\ignorespaces Minimization occurs in the codomain.}}{65}
\contentsline {figure}{\numberline {5.4}{\ignorespaces Data vector $T = {{\color {blue} {T_{ \mathcal {R} }}}} + {{\color {red} {T_{ \mathcal {N} }}}}$ resolved into range and null space components as in figure 2.3\hbox {}.}}{65}
\contentsline {figure}{\numberline {5.5}{\ignorespaces Decomposing $\left \delimiter 69645069 {\color {red} {r}} = {\color {red} {T_{ \mathcal {N} }}} \right \delimiter 86422285 _{2}^{2}$ into residual error terms $r_{k}^2$ of table 5.3\hbox {}.}}{65}
\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {7.1}{\ignorespaces Solution after translation along $x$ axis: the slope is invariant.}}{77}
\contentsline {figure}{\numberline {7.2}{\ignorespaces Scatter plot of residual errors.}}{78}
\contentsline {figure}{\numberline {7.3}{\ignorespaces The merit function after translation.}}{79}
\contentsline {figure}{\numberline {7.4}{\ignorespaces The merit function for the learning curve showing the minimum and the value.}}{80}
\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {9.1}{\ignorespaces A slice of a face-centered cubic lattice showing a single crystal.}}{85}
\contentsline {figure}{\numberline {9.2}{\ignorespaces Simulation output showing atomic shades shaded by potential energy.}}{86}
\contentsline {figure}{\numberline {9.3}{\ignorespaces Full data set showing inset.}}{87}
\contentsline {figure}{\numberline {9.4}{\ignorespaces Sample data set showing fit parameters.}}{87}
\contentsline {figure}{\numberline {9.5}{\ignorespaces Solutions for three data sets.}}{91}
\contentsline {figure}{\numberline {9.6}{\ignorespaces Apex angles displayed in table 9.7\hbox {}.}}{94}
\contentsline {figure}{\numberline {9.7}{\ignorespaces Merit functions for the three data sets.}}{95}
\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {11.1}{\ignorespaces Stitching local maps together to form a global map.}}{99}
\contentsline {figure}{\numberline {11.2}{\ignorespaces The ideal potential function showing five measurement zones and four overlap bands.}}{101}
\contentsline {figure}{\numberline {11.3}{\ignorespaces Waterfall diagram showing discretization within measurement zones with left and right zone overlaps.}}{101}
\contentsline {figure}{\numberline {11.4}{\ignorespaces Stitching unifies the data.}}{102}
\contentsline {figure}{\numberline {11.5}{\ignorespaces A set of piston adjustments which restores continuity across the domain.}}{102}
\contentsline {figure}{\numberline {11.6}{\ignorespaces Looking at the merit function on the $p_{2} - p_{3}$ axis.}}{107}
\contentsline {figure}{\numberline {11.7}{\ignorespaces Pistons from the solution and pistons used to create the data}}{108}
\contentsline {figure}{\numberline {11.8}{\ignorespaces A set of tilt adjustments which restores continuity of the gradient across the domain.}}{109}
\contentsline {figure}{\numberline {11.9}{\ignorespaces A function and its gradient.}}{109}
\addvspace {10\p@ }
\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {14.1}{\ignorespaces Merit function for the learning curve in solution space.}}{123}
\contentsline {figure}{\numberline {14.2}{\ignorespaces Merit function constrained to one parameter $b$.}}{125}
\contentsline {figure}{\numberline {14.3}{\ignorespaces Merit function for the learning curve in solution space showing the constrained $a$ parameter as a dotted line.}}{126}
\contentsline {figure}{\numberline {14.4}{\ignorespaces Solution for equations \textup {\hbox {\mathsurround \z@ \normalfont (\ignorespaces 14.2\hbox {}\unskip \@@italiccorr )}} and \textup {\hbox {\mathsurround \z@ \normalfont (\ignorespaces 14.3\hbox {}\unskip \@@italiccorr )}} using data in table 14.2\hbox {}.}}{126}
\contentsline {figure}{\numberline {14.5}{\ignorespaces The residual errors in figure 14.4\hbox {}.}}{127}
\contentsline {figure}{\numberline {14.6}{\ignorespaces Minimization of the merit function for the learning curve.}}{128}
\contentsline {figure}{\numberline {14.7}{\ignorespaces The merit function for the learning curve showing the minimum and the value .}}{129}
\contentsline {figure}{\numberline {14.8}{\ignorespaces The merit function for the radioactive decay model showing the minimum and the value .}}{131}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {15.1}{\ignorespaces Residual error for \textup {\hbox {\mathsurround \z@ \normalfont (\ignorespaces 15.3\hbox {}\unskip \@@italiccorr )}} with $a_{1}$, $a_{2}$, and $a_{3}$ at optimal values.}}{137}
\contentsline {figure}{\numberline {15.2}{\ignorespaces Residual error for $a_{1}$ and $a_{2}$ fixed at optimal values.}}{138}
\contentsline {figure}{\numberline {15.3}{\ignorespaces Solution plotted against data.}}{138}
\contentsline {figure}{\numberline {15.4}{\ignorespaces Scatterplot of residual errors.}}{139}
\contentsline {figure}{\numberline {15.5}{\ignorespaces The merit function showing least squares solution.}}{139}
\contentsline {figure}{\numberline {15.6}{\ignorespaces The merit function showing least squares solution and the null cline.}}{140}
\contentsline {figure}{\numberline {15.7}{\ignorespaces Total error $r^{\mathrm {*}}r$ by order of fit.}}{145}
\addvspace {10\p@ }
